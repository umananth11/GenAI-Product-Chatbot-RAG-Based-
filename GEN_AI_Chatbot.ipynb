{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1Fq7zGRSTNe"
      },
      "outputs": [],
      "source": [
        "#Set up your environment\n",
        "!pip install -q pandas numpy tqdm \\\n",
        "  transformers datasets peft trl accelerate bitsandbytes sentencepiece \\\n",
        "  sentence-transformers faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjIZOaaaTPFY"
      },
      "source": [
        "**2.Data Understanding and Preparation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DupXjLbh6ImE"
      },
      "outputs": [],
      "source": [
        "#Upload Data File\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzGFUwXr8qmE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('flipkart_com-ecommerce_sample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rq4-Mzim89j_"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TGwX7amHKGm"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gK_MWjaP9p41"
      },
      "outputs": [],
      "source": [
        "#Select ONLY useful columns\n",
        "df=df[['product_name','description','product_category_tree','brand','retail_price','discounted_price','pid']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLL3XjXzASsg"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cbvdj-jWEYw"
      },
      "outputs": [],
      "source": [
        "Brand_Missing_Value_Proportion =(df['brand'].notnull()).sum()/len(df)\n",
        "Brand_Missing_Value_Proportion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPXyzW5hV3Ll"
      },
      "outputs": [],
      "source": [
        "#Filling Misising Value:\n",
        "df['brand']=df['brand'].fillna('Brand Not Avaiable')\n",
        "df['description']=df['description'].fillna('Description Not Avaiable')\n",
        "df['retail_price']=df['retail_price'].fillna('retail price Not Available')\n",
        "df['discounted_price']=df['discounted_price'].fillna('discounted Price Not Avaiable')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riHfUIEqf26X"
      },
      "outputs": [],
      "source": [
        "df=df.dropna(subset=['description','product_name'])\n",
        "df.reset_index(drop=True)\n",
        "df['description']=df['description'].str.replace(r'<.*?>',\"\",regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNG9EOEcP3CQ"
      },
      "outputs": [],
      "source": [
        "#Create ‚ÄúProduct Documents\n",
        "def create_product_doc(row):\n",
        "  return f\"\"\"\n",
        "  Product Name:{row['product_name']}\n",
        "  Brand:{row['brand']}\n",
        "  Category:{row['product_category_tree']}\n",
        "  Retail Price:{row['retail_price']}\n",
        "  Discounted Price:{row['discounted_price']}\n",
        "  Description:{row['description']}\n",
        "  Product ID:{row['pid']}\n",
        "  \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_m1h0TQYDQq"
      },
      "outputs": [],
      "source": [
        "df['product Document']=df.apply(create_product_doc,axis=1)\n",
        "print(df['product Document'].iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiexqtIyhiOY"
      },
      "outputs": [],
      "source": [
        "#Reduce dataset size\n",
        "df=df.sample(500,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7kcXGE_isnK"
      },
      "outputs": [],
      "source": [
        "#Save cleaned data\n",
        "df.to_csv('clean_flipkart_products.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV0hBYv2Gdmf"
      },
      "outputs": [],
      "source": [
        "#Load the cleaned product data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "df=pd.read_csv('clean_flipkart_products.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L279WWkvcyKk"
      },
      "source": [
        "**3.Embeddings & Indexing:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpvbx-Y7NIZS"
      },
      "outputs": [],
      "source": [
        "#Load the Embedding Model\n",
        "from sentence_transformers import SentenceTransformer\n",
        "model=SentenceTransformer('all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F423tz-qqpsv"
      },
      "outputs": [],
      "source": [
        "#metadata management:\n",
        "def refine_product_type(row):\n",
        "    text = (row[\"product_name\"] + \" \" + row[\"description\"]).lower()\n",
        "\n",
        "    # SMARTPHONES\n",
        "    if any(x in text for x in [\"gb\",\"ram\",\"camera\",\"mah\",\"android\",\"ios\"]) and not any(x in text for x in [\"headset\",\"earphone\",\"charger\",\"usb\",\"fan\",\"lcd\",\"screen\",\"battery replacement\"]):\n",
        "      return \"smartphone\"\n",
        "\n",
        "    # FEATURE PHONES\n",
        "    if any(x in text for x in [\"feature phone\", \"keypad phone\", \"basic phone\"]):\n",
        "        return \"feature_phone\"\n",
        "\n",
        "    # MOBILE SPARES\n",
        "    if any(x in text for x in [\"lcd\", \"display\", \"touch screen\", \"digitizer\"]):\n",
        "        return \"lcd_spare\"\n",
        "    if \"battery\" in text and \"mah\" in text:\n",
        "        return \"battery_spare\"\n",
        "\n",
        "    # AUDIO ACCESSORIES\n",
        "    if any(x in text for x in [\"headset\", \"earphone\", \"earbud\", \"headphone\"]):\n",
        "        return \"audio_accessory\"\n",
        "\n",
        "    # FANS\n",
        "    if any(x in text for x in [\"usb fan\", \"cooling fan\"]):\n",
        "        return \"fan\"\n",
        "\n",
        "    # FOOTWEAR\n",
        "    if any(x in text for x in [\"shoe\", \"boot\", \"sneaker\"]):\n",
        "        return \"shoe\"\n",
        "    if any(x in text for x in [\"slipper\", \"sandal\"]):\n",
        "        return \"slipper\"\n",
        "\n",
        "    # WATCHES\n",
        "    if \"watch\" in text:\n",
        "        return \"watch\"\n",
        "\n",
        "    return \"other\"\n",
        "    df = df[df[\"product_type\"] != \"other\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SP1LWjWBrIkZ"
      },
      "outputs": [],
      "source": [
        "df[\"product_type\"] = df.apply(refine_product_type, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oa3kUbsiRkkN"
      },
      "outputs": [],
      "source": [
        "df[\"product_type\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJm2DqvNtEhO"
      },
      "outputs": [],
      "source": [
        "#Create Product-Type DataFrames\n",
        "smartphone_df= df[df[\"product_type\"] == \"smartphone\"]\n",
        "feature_phone_df= df[df[\"product_type\"] == \"feature_phone\"]\n",
        "lcd_spare_df= df[df[\"product_type\"] == \"lcd_spare\"]\n",
        "battery_spare_df= df[df[\"product_type\"] == \"battery_spare\"]\n",
        "audio_accessory_df=df[df[\"product_type\"]==\"audio_accessory\"]\n",
        "fan_df=df[df[\"product_type\"]==\"fan\"]\n",
        "shoe_df= df[df[\"product_type\"] == \"footwear\"]\n",
        "slipper_df= df[df[\"product_type\"] == \"slipper\"]\n",
        "watch_df= df[df[\"product_type\"] == \"watch\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crM5pjXbX8TG"
      },
      "outputs": [],
      "source": [
        "#Chucking\n",
        "from collections import defaultdict\n",
        "\n",
        "def chunk_text(text, chunk_size, overlap):\n",
        "    tokens = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(tokens), chunk_size - overlap):\n",
        "        chunk = \" \".join(tokens[i:i + chunk_size])\n",
        "        chunks.append(chunk)\n",
        "    return chunks\n",
        "\n",
        "type_chunks = defaultdict(list)\n",
        "type_chunk_meta = defaultdict(list)\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    ptype = row[\"product_type\"]\n",
        "    doc = row[\"product Document\"]\n",
        "\n",
        "    chunks = chunk_text(doc, 400, 50)\n",
        "\n",
        "    for ch in chunks:\n",
        "        type_chunks[ptype].append(ch)\n",
        "        type_chunk_meta[ptype].append(row[\"product_name\"])   # for debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dqh94FeIVk2j"
      },
      "outputs": [],
      "source": [
        "#Generate embeddings per product type\n",
        "type_embedding={}\n",
        "for ptype,chunks in type_chunks.items():\n",
        "  type_embedding[ptype]=model.encode(chunks,show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHUwOMvK_bjC"
      },
      "outputs": [],
      "source": [
        "#Intra-product-type similarity (Are phones close to phones?)\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "phone_vecs = type_embedding['watch']\n",
        "\n",
        "# pick 5 random phone chunks\n",
        "idx = np.random.choice(len(phone_vecs), 5, replace=False)\n",
        "sample = phone_vecs[idx]\n",
        "\n",
        "print(cosine_similarity(sample, sample))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64iDAxfHKV6J"
      },
      "source": [
        "‚ÄúWe evaluated embedding coherence using intra-type cosine similarity and refined product taxonomy until each FAISS index represented a semantically tight domain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4AZmqVXAFyC"
      },
      "outputs": [],
      "source": [
        "#Inter-product-type similarity (Are phones far from fans?)\n",
        "#‚ÄúWe embed the query, compute cosine similarity against product embeddings, and retrieve the most relevant product chunks.‚Äù\n",
        "phone_vec = type_embedding[\"smartphone\"][0]\n",
        "fan_vec   = type_embedding[\"watch\"][0]\n",
        "\n",
        "print(cosine_similarity([phone_vec],[fan_vec]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2UQEKr0Avga"
      },
      "outputs": [],
      "source": [
        "#Chunk relevance test\n",
        "q = model.encode(\"mobile phone with good battery\")\n",
        "\n",
        "scores = cosine_similarity([q], type_embedding[\"smartphone\"])\n",
        "top = scores.argsort()[0][-5:][::-1]\n",
        "\n",
        "for i in top:\n",
        "    print(type_chunks[\"smartphone\"][i][:150])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0OjyTqzHlBg"
      },
      "outputs": [],
      "source": [
        "#Build FAISS index per product type\n",
        "import faiss\n",
        "type_indexs={}\n",
        "for ptype,emb in type_embedding.items():\n",
        "  dim=emb.shape[1]\n",
        "  index=faiss.IndexFlatL2(dim)\n",
        "  index.add(emb)\n",
        "  type_indexs[ptype]=index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeZd9hjLHRz2"
      },
      "outputs": [],
      "source": [
        "emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS6wqyumm8hM"
      },
      "outputs": [],
      "source": [
        "#Route queries using product type\n",
        "def route_by_type(query):\n",
        "    q = query.lower()\n",
        "    if any(x in q for x in [\"gb\",\"ram\",\"camera\",\"mah\",\"android\",\"ios\"]) and not any(x in q for x in [\"headset\",\"earphone\",\"charger\",\"usb\",\"fan\",\"lcd\",\"screen\",\"battery replacement\"]):\n",
        "      return \"smartphone\"\n",
        "    if any(x in q for x in [\"feature phone\",\"keypad phone\"]):\n",
        "        return \"feature_phone\"\n",
        "\n",
        "    if any(x in q for x in [\"lcd\",\"screen\",\"display\",\"touch\"]):\n",
        "        return \"lcd_spare\"\n",
        "\n",
        "    if any(x in q for x in [\"battery replacement\",\"phone battery\"]):\n",
        "        return \"battery_spare\"\n",
        "\n",
        "    if any(x in q for x in [\"headset\",\"earphone\",\"earbud\",\"headphone\"]):\n",
        "        return \"audio_accessory\"\n",
        "\n",
        "    if any(x in q for x in [\"usb fan\",\"cooling fan\",\"fan\"]):\n",
        "        return \"fan\"\n",
        "\n",
        "    if any(x in q for x in [\"shoe\",\"boot\",\"sneaker\"]):\n",
        "        return \"shoe\"\n",
        "\n",
        "    if any(x in q for x in [\"slipper\",\"sandal\"]):\n",
        "        return \"slipper\"\n",
        "\n",
        "    if \"watch\" in q:\n",
        "        return \"watch\"\n",
        "\n",
        "    return \"other\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbcYk10RdMj5"
      },
      "source": [
        "**4.Retrieval Design (RAG)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmIFFmTZoigy"
      },
      "outputs": [],
      "source": [
        "#Build smart retrieval\n",
        "def smart_search(query,k=5):\n",
        "    ptype=route_by_type(query)\n",
        "\n",
        "    index= type_indexs.get(ptype)\n",
        "    chunks=type_chunks.get(ptype)\n",
        "\n",
        "    q_emb=model.encode(query)\n",
        "    scores,idxs=index.search(np.array([q_emb]),k)\n",
        "    return [chunks[i] for i in idxs[0]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Validate\n",
        "queries = [\n",
        "  \"mobile phone with good battery\",\n",
        "  \"iphone smartphone\",\n",
        "  \"usb cooling fan\",\n",
        "  \"women shoe\",\n",
        "  \"analog watch for women\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    print(\"\\nQUERY:\", q)\n",
        "    for r in smart_search(q):\n",
        "        print(\"-\", r[:120])"
      ],
      "metadata": {
        "id": "MVKkwKVQ3oxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdIT9NPk8wTN"
      },
      "source": [
        "Inference:‚ÄúProduct catalogue text is converted into dense vector embeddings using a sentence transformer. These embeddings are indexed using FAISS for fast semantic similarity search. At query time, the user question is embedded and matched against product vectors to retrieve relevant product information.‚Äù"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwhfBAyj8l2k"
      },
      "source": [
        "‚ÄúBefore integrating the LLM, we evaluated embedding quality using cosine similarity and intra-type vs inter-type comparisons. We validated FAISS retrieval using manual Top-K inspection and Recall@K to ensure accurate, type-safe retrieval.‚Äù\n",
        "Recall@5 = hits / total_queries\n",
        "Embeddings understand meaning, FAISS proves retrieval, LLM only speaks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAscTdjzdjAC"
      },
      "source": [
        "**5.LLM Integration**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49nQBc1d3T_v"
      },
      "source": [
        "#Prepare Fine-Tuning Dataset (Style Only)\n",
        "\n",
        "Create Q&A examples that show:\n",
        "\n",
        "How answers should look\n",
        "\n",
        "How prices are described\n",
        "\n",
        "How comparisons are explained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWxXQx9CI5QA"
      },
      "outputs": [],
      "source": [
        "examples=[\n",
        "    {\"prompt\":\"User: Tell me about a smartphone with good battery\\nAssistant:\",\n",
        " \"response\":\"Sure! Here are some smartphones with long-lasting battery performance. I‚Äôll show you the best options based on your budget and preferences.\"},\n",
        "    {\"prompt\":\"User: Suggest a good phone for students\\nAssistant:\",\n",
        " \"response\":\"Great choice! Student-friendly phones should have good battery life, decent performance, and affordable pricing. Let me find the best options for you.\"},\n",
        "    {\"prompt\":\"User: Compare two smartphones\\nAssistant:\",\n",
        " \"response\":\"Here‚Äôs a simple comparison to help you choose:\\n\\n‚Ä¢ Battery life\\n‚Ä¢ Camera quality\\n‚Ä¢ Performance\\n‚Ä¢ Storage\\n\\nLet me know which matters most to you!\"},\n",
        "    {\"prompt\":\"User: Best phone under 15000\\nAssistant:\",\n",
        " \"response\":\"Sure! I‚Äôll find the best smartphones under ‚Çπ15,000 with good battery, camera, and performance. Please tell me if you prefer any brand.\"},\n",
        "    {\"prompt\":\"User: What is the warranty of Samsung Galaxy M34?\\nAssistant:\",\n",
        " \"response\":\"I‚Äôll check the product details to give you the correct warranty information. If it‚Äôs not available, I‚Äôll let you know honestly.\"},\n",
        "    {\"prompt\":\"User: Is this phone waterproof?\\nAssistant:\",\n",
        " \"response\":\"Let me verify the product specifications. If waterproofing information is not listed, I won‚Äôt assume it.\"},\n",
        "    {\"prompt\":\"User: I want a phone for photography\\nAssistant:\",\n",
        " \"response\":\"Great! Camera quality is important. I‚Äôll recommend phones with the best camera features. Do you have a budget range?\"},\n",
        "    {\"prompt\":\"User: I want shoes for daily use\\nAssistant:\",\n",
        " \"response\":\"Nice! Comfortable shoes for daily use should have good cushioning and durability. I‚Äôll suggest suitable options for you.\"},\n",
        "    {\"prompt\":\"User: Hi\\nAssistant:\",\n",
        " \"response\":\"Hello! üëã I‚Äôm your Flipkart product assistant. How can I help you today?\"},\n",
        "    {\"prompt\":\"User: Thanks\\nAssistant:\",\n",
        " \"response\":\"You‚Äôre welcome! üòä Let me know if you need help choosing the perfect product.\"},\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IrevPZ9MVq9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('fine_tune_dataset.jsonl','w',encoding='utf-8') as f:\n",
        "  for ex in examples:\n",
        "    f.write(json.dumps(ex,ensure_ascii=False)+'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QpqogYl7Jhs"
      },
      "source": [
        "We use JSON because it clearly separates input and output for supervised fine-tuning, making it easy for the LLM to learn prompt-response mapping in a structured, machine-readable format."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "BASE_MODEL = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    load_in_8bit=True,\n",
        "    device_map=\"auto\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "IUhUIYxl7ERm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWX_0-OudwUL"
      },
      "source": [
        "**6.Fine-Tuning (LoRA)**-[LORA-Low Rank Adapter]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTi535f9KVir"
      },
      "outputs": [],
      "source": [
        "#Configure LoRA\n",
        "from peft import LoraConfig # PEFT (Parameter-Efficient Fine-Tuning)\n",
        "lora_config=LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=['q_proj','v_proj'], # Corrected typo from 'v_=proj' to 'v_proj'\n",
        "    lora_dropout=0.05,\n",
        "    bias='none',\n",
        "    task_type='CAUSAL_LM'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "184iCoHl39or"
      },
      "outputs": [],
      "source": [
        "#Load Fine-Tuning Dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "def format_for_sft(example):\n",
        "    example[\"text\"] = example[\"prompt\"] + example[\"response\"]\n",
        "    return example\n",
        "\n",
        "dataset = load_dataset('json', data_files='fine_tune_dataset.jsonl', split='train')\n",
        "dataset = dataset.map(format_for_sft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suOevnDo4Ama"
      },
      "outputs": [],
      "source": [
        "#Pre-tokenize your dataset manually\n",
        "def tokenize_fn(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_fn, batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FinE Tuning:\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=10,\n",
        "    # Changed fp16=True to bf16=True for potentially better compatibility\n",
        "    bf16=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    peft_config=lora_config,\n",
        "    args=training_args\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "UBn5ZxUi-ReH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbVhKt9ItyDg"
      },
      "outputs": [],
      "source": [
        "#Save Adapter\n",
        "trainer.model.save_pretrained(\"flipkart-style-lora\")\n",
        "tokenizer.save_pretrained(\"flipkart-style-lora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We save the fine-tuned LoRA adapters and tokenizer so the model can be reloaded later without storing the full base model."
      ],
      "metadata": {
        "id": "axjtLg85BvCc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLz1CC9i276j"
      },
      "outputs": [],
      "source": [
        "#Inference (RAG + Fine-Tuned LLM)\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "base = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "model = PeftModel.from_pretrained(base, \"flipkart-style-lora\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXpXnENUyVFh"
      },
      "outputs": [],
      "source": [
        "def answer_question(query):\n",
        "    retrieved_chunks = smart_search(query)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a Flipkart Product Assistant.\n",
        "    Answer ONLY using the context below.\n",
        "    If not found, say you don‚Äôt know.\n",
        "\n",
        "    Context:\n",
        "    {'\\n'.join(retrieved_chunks)}\n",
        "\n",
        "    User: {query}\n",
        "    Assistant:\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=300,\n",
        "            temperature=0.3,\n",
        "            top_p=0.9,\n",
        "            do_sample=True\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt Template:**‚ÄúThis prompt combines instruction tuning with RAG by injecting retrieved knowledge into the context and explicitly restricting the model to answer only from that context, which significantly reduces hallucinations."
      ],
      "metadata": {
        "id": "JweTFxOpBczT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6QWm15A1nC-"
      },
      "source": [
        "\n",
        "**This is a hybrid RAG + PEFT(Performance Efficient Fine Tuning) architecture.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovuIUQklnxY2"
      },
      "source": [
        "‚ÄúWe are plannig to use  OpenAI Whisper to transcribe Tamil speech into text.\n",
        "The transcribed Tamil text is translated to English using Hugging Face Transformers (opus-mt-ta-en) so it can be processed against English product data.\n",
        "After generating the response, we translate it back to Tamil using opus-mt-en-ta.\n",
        "Finally, we convert the Tamil text into speech using GTTS(Google Text-to-Speech) for multilingual voice output.‚Äù"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_9E4yVxWAdX"
      },
      "source": [
        "**9. Deployment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IEGm7KzX7Iq"
      },
      "source": [
        "**9.1 Fast API:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CK_sUzuytkd"
      },
      "source": [
        "***9.1.1. Install API dependencies***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PThxcApEWU8q"
      },
      "outputs": [],
      "source": [
        "pip install nest-asyncio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUE9oN-zy_dF"
      },
      "source": [
        "***9.1.3.Create FastAPI app***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAd5QH__dcHB"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "app=FastAPI(title=\"GenAI Product Chatbot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TssjI_QzK7k"
      },
      "source": [
        "***9.1.4.Define request / response schema***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZtSYMrYg-M-"
      },
      "outputs": [],
      "source": [
        "class ChatRequest(BaseModel):\n",
        " question:str\n",
        "class ChatResponse(BaseModel):\n",
        " answer:str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjHrYUwjyqOq"
      },
      "source": [
        "***9.1.5.Create /chat endpoint***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_8Z1RFemTpo"
      },
      "outputs": [],
      "source": [
        "@app.post('/chat',response_model=ChatResponse)\n",
        "def chat(request:ChatRequest):\n",
        "  context=retrieve_context(request.question)\n",
        "  answer=generate_answer(request.question,context)\n",
        "  return {'answer':answer}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r494KRcL3SuF"
      },
      "source": [
        "***9.1.6. Run FastAPI from notebook***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfjjyONH_L1R"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import uvicorn\n",
        "\n",
        "def run_api():\n",
        "    uvicorn.run(\n",
        "        app,\n",
        "        host=\"0.0.0.0\",\n",
        "        port=8000,\n",
        "        log_level=\"info\"\n",
        "    )\n",
        "\n",
        "thread = threading.Thread(target=run_api, daemon=True)\n",
        "thread.start()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IlSR-aUi3T4"
      },
      "outputs": [],
      "source": [
        "!./cloudflared-linux-amd64 tunnel --url http://localhost:8000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-g6AGgtrGPU"
      },
      "source": [
        "FastAPI defines the API; Uvicorn runs it.\n",
        "Cloudflare Tunnel is a secure way to expose your local application to the internet without opening any ports.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}